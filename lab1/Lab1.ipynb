{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.data' \n",
    "segmentation_data = pd.read_csv(seg_data_url, sep=',', skiprows=2)\n",
    "print(segmentation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_test_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/image/segmentation.test' \n",
    "segmentation_test = pd.read_csv(seg_test_url, sep=',', skiprows=2)\n",
    "print(segmentation_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([segmentation_data, segmentation_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add index and class column\n",
    "data= data.reset_index()\n",
    "data= data.rename(columns={'index': 'Class'})\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of instances  = 2310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of attributes = 19\n",
    "*one column for className* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data['Class'].unique()\n",
    "print(\"class names : \",  classes)\n",
    "print(\"number of classes: \", len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Explortions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_lists(class_name):\n",
    "    \n",
    "    # select data with specefic class_name\n",
    "    new_data = data.loc[data['Class'] == class_name]\n",
    "    data_to_plot = []\n",
    "    \n",
    "    # make each columns as list and return data as list of lists\n",
    "    i = 1\n",
    "    while i < len(new_data.columns):\n",
    "        column_list = list(new_data.iloc[:,i])\n",
    "        data_to_plot.append(column_list)\n",
    "        i = i + 1\n",
    "    return data_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare colors and lablel names of the images\n",
    "list1 = sns.color_palette(\"husl\", 7)\n",
    "list1 += sns.color_palette(\"Paired\")\n",
    "colors = list1\n",
    "column_names = list(data.columns.values)[1:]\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot for different bin sizes\n",
    "for j, bin in enumerate([1, 5, 10, 15]):\n",
    "    f = plt.figure(figsize=(40,100))\n",
    "    # plot for each class\n",
    "    for i, class_name in enumerate(classes):\n",
    "        \n",
    "        # Set up the plot\n",
    "        ax = f.add_subplot(42*10+i+1)\n",
    "        \n",
    "        # Draw the plot\n",
    "        data_to_plot = get_list_of_lists(class_name)\n",
    "        ax.hist(data_to_plot, bins = bin, density = True, color = colors, label = column_names)\n",
    "        \n",
    "        # Title and labels\n",
    "        ax.set_title('Class = %s' %class_name, size = 30)\n",
    "        ax.set_xlabel('Attributes', size = 22)\n",
    "        ax.set_ylabel('Values', size= 22)\n",
    "        ax.legend()\n",
    "\n",
    "    f.suptitle('Histogram with Bins = %d' % bin, size = 50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxblot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = data.boxplot(column=column_names, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(data):\n",
    "    correlations = data.corr(method='pearson')\n",
    "    fig, ax = plt.subplots(figsize=(20,20))\n",
    "    sns.heatmap(correlations, vmax=1.0, center=0, fmt='.2f',\n",
    "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\n",
    "    plt.show();\n",
    "    \n",
    "correlation_heatmap(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip applying 'Min-Max scaler' on constant columns and string ones\n",
    "cols = data.columns.difference(['Class', 'REGION-PIXEL-COUNT'])\n",
    "x = data[cols].values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "data_normalized_Min_Max_scaler = pd.DataFrame(x_scaled, columns = cols)\n",
    "data_normalized_Min_Max_scaler.insert(0,'Class',data.iloc[:,0].values, True)\n",
    "data_normalized_Min_Max_scaler.insert(3,'REGION-PIXEL-COUNT',data.iloc[:,3].values, True)\n",
    "data_normalized_Min_Max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = data_normalized_Min_Max_scaler.boxplot(column=column_names, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The result data spread on a very small scale, so values are more close to each other.\n",
    "- With min-max normalization, we were guaranteed to reshape both of our features to be between 0 and 1.\n",
    "- doesn't handle outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.columns[1:]\n",
    "x = data[cols] \n",
    "# skip applying 'z-score' on constant columns\n",
    "x_scaled = x.apply(lambda x: x if np.std(x) == 0 else zscore(x)) \n",
    "data_normalized_Z_score = pd.DataFrame(x_scaled, columns = cols)\n",
    "data_normalized_Z_score.insert(0,'Class',data.iloc[:,0].values, True)\n",
    "data_normalized_Z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = data_normalized_Z_score.boxplot(column=column_names, figsize=(40,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The result data spread on less scale, so valuse are more close to each other.\n",
    " -  A value is exactly equal to the mean of all the values of the feature, it will be normalized to 0. If it is below the mean, it will be a negative number, and if it is above the mean it will be a positive number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate columns names for pca and feture selection\n",
    "pca_columns =[] \n",
    "feature_columns = []\n",
    "for i in range(1,11):\n",
    "    pca_columns.append('principal component {}'.format(i))\n",
    "    feature_columns.append('Feture {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass desired sum of varince ratio we need to be captured \n",
    "pca = PCA(0.95)\n",
    "principalComponents = pca.fit_transform(data_normalized_Z_score.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = pd.DataFrame(principalComponents, columns = pca_columns)\n",
    "pca_data.insert(0,'Class',data.iloc[:,0].values, True)\n",
    "correlation_heatmap(pca_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "\n",
    "- Principal component analysis convert a set of observations of correlated variables into a set of values of linearly uncorrelated variables called principal components\n",
    "\n",
    "- less than the half of attributes cn describe the data with 0.95 percent  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "applied on 'z-score' normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_best = SelectKBest(k=10)\n",
    "sk_best_data = sk_best.fit_transform(data_normalized_Z_score.iloc[:,1:],data_normalized_Z_score.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_best.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_best_data = pd.DataFrame(sk_best_data, columns = feature_columns)\n",
    "sk_best_data.insert(0,'Class',data.iloc[:,0].values, True)\n",
    "correlation_heatmap(sk_best_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- Feature Selection select those features which contribute most to your prediction variable or output in which you are interested in.\n",
    "\n",
    "- These features are highly correlated  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
